# Recursive Web Crawler User Manual

This program is a Web Crawler that will take two command line arguments, the first being and absolute URL only using the 
HTTP and HTTPS schemes. The second argument being the depth it should crawl; this is an optional argument the default is
set to a depth of 3.

Once given it will print out the urls visited with the depth represented by a tab in the output. You can also you the
standard Keyboard Interrupt to stop the program at anytime.
